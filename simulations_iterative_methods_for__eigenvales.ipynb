{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "suapmU5JEWV4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "4698bf2c-fa62-4bd8-9b11-1b694a98b9f6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matrix_tools'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b5a6da230864>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatrix_tools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matrix_tools'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from matplotlib.pylab import LinAlgError\n",
        "from matplotlib.widgets import EllipseSelector\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "from sympy import use\n",
        "import matrix_tools as mt\n",
        "import time\n",
        "\n",
        "from scipy import sparse as sps\n",
        "from scipy.linalg import eigh,inv,lu_factor,lu_solve\n",
        "from scipy.linalg.lapack import dsyev\n",
        "from numpy.linalg import norm\n",
        "import scipy.linalg as la\n",
        "from scipy.sparse import linalg as lin\n",
        "from scipy.sparse.linalg import inv as spinv\n",
        "import pdb,time,warnings\n",
        "np.seterr(all='raise')\n",
        "\n",
        "#logging\n",
        "import datetime\n",
        "from loguru import logger\n",
        "import sys        # <!- add this line\n",
        "logger.remove()             # <- add this line\n",
        "logger.add(sys.stdout, level=\"INFO\")   # <- add this line\n",
        "log_format = \"<green>{time:YYYY-MM-DD HH:mm:ss.SSS zz}</green> | <level>{level: <8}</level> | <yellow>Line {line: >4} ({file}):</yellow> <b>{message}</b>\"\n",
        "log_path=\".\\logs\\log-\"+str(datetime.datetime.now()).replace(\" \",\"-\").replace(\".\",\"-\").replace(\":\",\"-\")+\".log\"\n",
        "logger.add(log_path, level=\"TRACE\", format=log_format, colorize=False, backtrace=True, diagnose=True)\n",
        "# Lanczos algorithm\n",
        "def lanczos_1(A, v0=None,maxiter=None):\n",
        "    start_time=time.time()\n",
        "    # First iteration steps\n",
        "    x, y = [], []\n",
        "    n = A.shape[0]\n",
        "    if maxiter is None:maxiter=n\n",
        "    v0 = np.random.random((n, 1))\n",
        "    v1, beta = 0.0, 0.0\n",
        "\n",
        "    for i in range(maxiter):\n",
        "        # Iteration steps\n",
        "        w_prime = np.dot(A, v0)\n",
        "        conj = np.matrix.conjugate(w_prime)\n",
        "        alpha = np.dot(conj, v0)\n",
        "        w = w_prime - alpha * v0 - beta * v1\n",
        "        beta = np.linalg.norm(w)\n",
        "        x.append(np.linalg.norm(alpha))\n",
        "\n",
        "        # Reset\n",
        "        if i < (maxiter-1):\n",
        "            y.append(beta)\n",
        "        v1 = v0\n",
        "        v0 = w/beta\n",
        "    end_time=time.time()\n",
        "    eigen_values, eigen_vectors=np.eig(mt.tridiag(y, x, y))\n",
        "\n",
        "    logger.success('Lancsoz Method '+ str(np.sort(eigen_values[0]))+'; time = '+str(end_time-start_time)+ \" seconds.\")\n",
        "\n",
        "    return eigen_values,eigen_vectors,end_time-start_time, maxiter\n",
        "def lanczos_2(A, maxiter=None):\n",
        "\n",
        "    start_time=time.time()\n",
        "    n = A.shape[0]\n",
        "    if maxiter is None:maxiter=n\n",
        "\n",
        "    v = np.random.random((n, 1))\n",
        "    v = v / np.linalg.norm(v)\n",
        "    v_old = np.zeros((n, 1))\n",
        "    beta = np.zeros(maxiter)\n",
        "    alpha = np.zeros(maxiter)\n",
        "    for j in range(maxiter-1):\n",
        "        w = A.dot(v)\n",
        "        alpha[j] = w.T.dot(v)\n",
        "        w = w - alpha[j] * v - beta[j] * v_old\n",
        "        beta[j+1] = np.linalg.norm(w)\n",
        "        v_old = v.copy()\n",
        "        v = w / beta[j+1]\n",
        "    w = A.dot(v)\n",
        "    alpha[maxiter-1] = w.T.dot(v)\n",
        "    A = np.diag(beta[1:], k=-1) + np.diag(beta[1:], k=1) + np.diag(alpha[:], k=0)\n",
        "    eigen_values, eigen_vectors = np.linalg.eigh(A)\n",
        "    end_time=time.time()\n",
        "    logger.success('Lancsoz Method '+ str(np.sort(eigen_values[0]))+'; time = '+str(end_time-start_time)+ \" seconds.\")\n",
        "    return eigen_values,eigen_vectors,end_time-start_time, maxiter\n",
        "\n",
        "def block_power_method(A, k, tol=1e-6, maxiter=100):\n",
        "\n",
        "    n = A.shape[0]\n",
        "    residauls=[]\n",
        "    approx_egien_values=[]\n",
        "    # Check if k is valid\n",
        "    if k < 1 or k > n:\n",
        "        print(\"Invalid value of k\")\n",
        "        return None\n",
        "    start_time=time.time()\n",
        "    # Initialize a random matrix Q of size n B k\n",
        "    Q = np.random.rand(n, k)\n",
        "\n",
        "    # Orthonormalize Q using QR decomposition\n",
        "    Q, _ = np.linalg.qr(Q)\n",
        "\n",
        "    # Initialize a variable to store the eigenvalues\n",
        "    lambdas = np.zeros(k)\n",
        "\n",
        "    # Initialize a counter for iterations\n",
        "    iter = 0\n",
        "\n",
        "    # Loop until convergence or maximum iterations\n",
        "    while iter < maxiter:\n",
        "        # Perform the matrix multiplication AQ\n",
        "        Z = A @ Q\n",
        "\n",
        "        # Solve the linear system Q^T Z = Q^T A Q = Lambda\n",
        "        # Lambda is a diagonal matrix of eigenvalues\n",
        "        # We can use np.linalg.solve to find Lambda\n",
        "        Lambda = np.linalg.solve(Q.T, Z.T).T\n",
        "\n",
        "        # Extract the diagonal elements of Lambda\n",
        "        lambdas_new = np.diag(Lambda)\n",
        "\n",
        "        # Check the relative change of eigenvalues\n",
        "        diff=lambdas - lambdas_new\n",
        "        res=np.linalg.norm(diff)\n",
        "        approx_egien_values.append(lambdas_new)\n",
        "        residauls.append(res)\n",
        "        if  res < tol:\n",
        "            logger.info('Block power method converged at iteration number = '+ str(iter))\n",
        "            # Converged\n",
        "            break\n",
        "\n",
        "        # Update the eigenvalues\n",
        "        lambdas = lambdas_new\n",
        "\n",
        "        # Orthonormalize Z using QR decomposition\n",
        "        Q, _ = np.linalg.qr(Z)\n",
        "\n",
        "        # Increment the iteration counter\n",
        "        iter += 1\n",
        "\n",
        "    end_time=time.time()\n",
        "    logger.success(\"Block Power method  = \"+ str(lambdas)+\"; time = \"+str(end_time-start_time)+\" seconds.\")\n",
        "\n",
        "    # Return the eigenvalues and eigenvectors\n",
        "    return lambdas, Q, end_time-start_time, iter,residauls,approx_egien_values\n",
        "\n",
        "def subspace_iteration_1(A, k=1, Y0=None, maxiter=100,tol=1e-6):\n",
        "    start_time=time.time()\n",
        "    n=A.shape[0]\n",
        "    residauls=[]\n",
        "    approx_egien_values=[]\n",
        "    if Y0 is None:\n",
        "        Y0 = np.random.random((n, k))\n",
        "\n",
        "    Y0, _ = np.linalg.qr(Y0)\n",
        "    Y = Y0.copy()\n",
        "    Y_old = Y0.copy()\n",
        "    err = []\n",
        "    i=0\n",
        "    while i<maxiter:\n",
        "        B = A.dot(Y)\n",
        "        Y, E = np.linalg.qr(B)\n",
        "        error=np.linalg.norm(Y_old - Y.dot(Y.T.dot(Y_old)))\n",
        "        residauls.append(error)\n",
        "        approx_egien_values.append(np.diag(E))\n",
        "        i+=1\n",
        "        if(error<tol):\n",
        "            logger.info('Subspace_1 converged at iteration number = '+ str(i))\n",
        "            break\n",
        "        Y_old = Y.copy()\n",
        "        end_time=time.time()\n",
        "\n",
        "    # approx = np.dot(Y.T,np.dot(A,Y))/np.linalg.norm(Y)\n",
        "\n",
        "    logger.success(\"Subspace iteration = \"+ str(np.diag(E))+\"; time = \"+str(end_time-start_time)+\" seconds.\")\n",
        "\n",
        "    return np.diag(E), Y,end_time-start_time, i,residauls,approx_egien_values\n",
        "\n",
        "def subspace_iteration_2(A, k=1, V0=None, maxiter=1000,tol=1e-4):\n",
        "\n",
        "    start_time=time.time()\n",
        "    n=A.shape[0]\n",
        "\n",
        "    if V0 is None:\n",
        "        V0 = np.random.random((n, k))\n",
        "\n",
        "    V=V0\n",
        "    residuals = []\n",
        "    approx_egien_values=[]\n",
        "    err=100\n",
        "    i=0\n",
        "    while i<maxiter:\n",
        "        B = A.dot(V)\n",
        "        Q, R = np.linalg.qr(B)\n",
        "        V=Q[:, :k]\n",
        "        E=R[:k, :]\n",
        "        err=np.linalg.norm(A.dot(V)-V.dot(E))\n",
        "        residuals.append(err)\n",
        "        approx_egien_values.append(np.diag(E))\n",
        "        i+=1\n",
        "        if(err<tol):\n",
        "            logger.info('Subspace_2 converged at iteration number = '+ str(i))\n",
        "            break\n",
        "\n",
        "    end_time=time.time()\n",
        "\n",
        "\n",
        "    logger.success(\"Subspace iteration_2 = \"+ str(np.diag(E))+\"; time = \"+str(end_time-start_time)+\" seconds.\")\n",
        "\n",
        "    return E, V,end_time-start_time,i, residuals, approx_egien_values\n",
        "\n",
        "def rayleigh_quotient_iteration(A, tol=1e-10, rcoeff=0, B=None):\n",
        "    n=A.shape[0]\n",
        "    residuals=[]\n",
        "\n",
        "    if B is None:\n",
        "        B=np.random.rand(n)\n",
        "    B = B / la.norm(B)\n",
        "\n",
        "    # the solve function in scipy.linalg solves a linear system\n",
        "    start_time=time.time()\n",
        "    try:\n",
        "        C = la.solve(A - rcoeff * np.eye(n), B)\n",
        "\n",
        "    except la.LinAlgError as exc:\n",
        "        # logger.exception(exc)\n",
        "        logger.warning(\"la.solve failed. Trying to use la_factor and la_solve.\")\n",
        "        try:\n",
        "            LU, piv = lu_factor(A - rcoeff * np.eye(n))\n",
        "            C=lu_solve((LU,piv),B)\n",
        "        except np.linalg.LinAlgError as exc:\n",
        "            # logger.exception(exc)\n",
        "            logger.warning(\"lu_solve and lu_factor failed. please try use_inverse\")\n",
        "            raise exc\n",
        "\n",
        "\n",
        "\n",
        "    lambda_ = C.T @ B\n",
        "    rcoeff = rcoeff + 1 / lambda_\n",
        "    err = la.norm(C - lambda_ * B) / la.norm(C)\n",
        "    residuals.append(err)\n",
        "    j=0\n",
        "    while err > tol:\n",
        "        j+=1\n",
        "        B = C / la.norm(C)\n",
        "        try:\n",
        "            C = la.solve(A - rcoeff * np.eye(n), B)\n",
        "\n",
        "        except la.LinAlgError as exc:\n",
        "            # logger.exception(exc)\n",
        "            logger.warning(\"la.solve failed. Trying to use la_factor and la_solve.\")\n",
        "            try:\n",
        "                LU, piv = lu_factor(A - rcoeff * np.eye(n))\n",
        "                C=lu_solve((LU,piv),B)\n",
        "            except np.linalg.LinAlgError as exc:\n",
        "                # logger.exception(exc)\n",
        "                logger.warning(\"lu_solve and lu_factor failed. please try use_inverse\")\n",
        "                raise exc\n",
        "        lambda_ = C.T @ B\n",
        "        rcoeff = rcoeff + 1 / lambda_\n",
        "        err = la.norm(C - lambda_ * B) / la.norm(C)\n",
        "\n",
        "    logger.info('Rayleigh Quotient Iteration converged at iteration number = '+ str(j))\n",
        "    # approx=np.dot(B.T,np.dot(A,B))/np.linalg.norm(B)\n",
        "    end_time=time.time()\n",
        "\n",
        "    # logger.success(' Reigh iteration '+ str(approx)+'; time = '+str(end_time-start_time)+ \" seconds.\")\n",
        "    logger.success('Rayleigh Quotient Iteration = '+ str(rcoeff)+'; time = '+str(end_time-start_time)+ \" seconds.\")\n",
        "\n",
        "    return rcoeff,B,residuals\n",
        "\n",
        "def power_iteration(A,tol=1e-10,maxiter=1000,use_rayleigh=False,calc_min=False,use_inverse=True,Sigma=0,norm_c_mode='2',output_approx_instead_of_residuals=False):\n",
        "    if calc_min:\n",
        "        method_name='Inverse iteration: use_inverse = {}, use_rayleigh = {}, norm_c_mode = {}'.format(use_inverse, use_rayleigh, norm_c_mode)\n",
        "    else:\n",
        "        method_name='Power iteration: use_inverse = {}, use_rayleigh = {}, norm_c_mode = {}'.format(use_inverse, use_rayleigh, norm_c_mode)\n",
        "    n=A.shape[0]\n",
        "    residuals=[]\n",
        "    approx_egien_values=[]\n",
        "    A_orginal=A.copy()\n",
        "    start_time = time.time()\n",
        "    A_Sigma=A_orginal-Sigma*np.eye(n)\n",
        "    A=A_Sigma.copy()\n",
        "    # if not calc_min and use_inverse:\n",
        "    #     logger.warning('Ignoring use_inverse. Use_inverse is an option when calc_min is set to True.')\n",
        "\n",
        "    if calc_min:\n",
        "        if use_inverse:\n",
        "            try :\n",
        "                A=np.linalg.inv(A)\n",
        "            except np.linalg.LinAlgError as exc:\n",
        "                # logger.exception(exc)\n",
        "                logger.warning(\"Matrix is singuar. Trying to use psudo inverse of A. Also you can turn off use_inverse flag for using lu_factor and lu_solver to solve the linear system. \")\n",
        "                A=np.linalg.pinv(A)\n",
        "        else:\n",
        "            if not use_rayleigh:\n",
        "\n",
        "                     LU,piv=lu_factor(A)\n",
        "    else:\n",
        "        if use_rayleigh:\n",
        "            logger.warning('calc_min is off. use_rayleigh is ignored.')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Build a random trial vector\n",
        "    B=np.random.rand(n)\n",
        "    B=B/la.norm(B)\n",
        "    j=0\n",
        "    rcoeff=0\n",
        "    norm_mat=np.zeros(2)\n",
        "    while j<maxiter:\n",
        "        if calc_min:\n",
        "            if use_rayleigh:\n",
        "\n",
        "                rcoeff = np.dot(B.T,np.dot(A,B))/np.linalg.norm(B)\n",
        "            if not use_inverse:\n",
        "                if use_rayleigh:\n",
        "\n",
        "                    try:\n",
        "                        C=la.solve(A_Sigma-rcoeff*np.eye(n),B)\n",
        "\n",
        "                    except (la.LinAlgError, la.LinAlgWarning) as exc:\n",
        "                        # logger.exception(exc)\n",
        "                        logger.warning(\"la.solve failed. Trying to use la_factor and la_solve.\")\n",
        "                        try:\n",
        "                            LU, piv = la.lu_factor(A_Sigma-rcoeff*np.eye(n))\n",
        "                            C=la.lu_solve((LU,piv),B)\n",
        "                            if(np.any(C==None) or np.any(C==np.inf)):\n",
        "                                logger.warning(\"lu_solve and lu_factor failed. please try use_inverse\")\n",
        "                                A_new=A_Sigma-rcoeff*np.eye(n)\n",
        "                                try :\n",
        "                                    A_new=np.linalg.inv(A_new)\n",
        "                                except np.linalg.LinAlgError as exc:\n",
        "\n",
        "                                    # logger.exception(exc)\n",
        "                                    logger.warning(\"Matrix is singuar. Trying to use psudo inverse of A_new. Also you can turn off use_inverse flag for using lu_factor and lu_solver to solve the linear system. \")\n",
        "                                    A_new=np.linalg.pinv(A_new)\n",
        "                                C =  np.dot(A_new,B)  if use_rayleigh else np.dot(A,B)\n",
        "\n",
        "                        except (la.LinAlgError, la.LinAlgWarning)  as exc:\n",
        "                            # logger.exception(exc)\n",
        "                            logger.warning(\"lu_solve and lu_factor failed. please try use_inverse\")\n",
        "                            # raise exc\n",
        "                else:\n",
        "                    C=lu_solve((LU,piv),B)\n",
        "                idx=np.argmax(np.abs(C))\n",
        "            else:\n",
        "                if use_rayleigh:\n",
        "                    A_new=A_Sigma-rcoeff*np.eye(n)\n",
        "                    try :\n",
        "                        A_new=np.linalg.inv(A_new)\n",
        "                    except np.linalg.LinAlgError as exc:\n",
        "\n",
        "                        # logger.exception(exc)\n",
        "                        logger.warning(\"Matrix is singuar. Trying to use psudo inverse of A_new. Also you can turn off use_inverse flag for using lu_factor and lu_solver to solve the linear system. \")\n",
        "                        A_new=np.linalg.pinv(A_new)\n",
        "\n",
        "                C =  np.dot(A_new,B)  if use_rayleigh else np.dot(A,B)\n",
        "        else:\n",
        "            C = np.dot(A,B)\n",
        "\n",
        "\n",
        "        norm_c = C[idx] if ( not use_inverse and calc_min and norm_c_mode=='max_abs') else np.linalg.norm(C)\n",
        "        B = C/(norm_c)\n",
        "        j=j+1\n",
        "        # print(j)\n",
        "        if j==1:\n",
        "            logger.trace('just the first iteration, give me a break')\n",
        "            norm_mat[0]=norm_c\n",
        "        else:\n",
        "            norm_mat[1] = norm_mat[0]\n",
        "            norm_mat[0] = norm_c\n",
        "            if( calc_min and use_rayleigh and not use_inverse):\n",
        "                diff=la.norm(C-(C.T@B)*B)\n",
        "            else:\n",
        "                diff = abs(norm_mat[1] - norm_mat[0])\n",
        "            residuals.append(diff)\n",
        "            if output_approx_instead_of_residuals:\n",
        "                approx = 1/norm_c if (calc_min and not use_inverse and norm_c_mode=='max_abs') else np.dot(B.T,np.dot(A,B))/np.linalg.norm(B)\n",
        "                if calc_min and use_inverse: approx=1./approx\n",
        "                approx += Sigma\n",
        "                approx_egien_values.append(approx)\n",
        "            if diff < tol:\n",
        "                logger.info('Power iteration converged at iteration number = '+ str(j))\n",
        "                break\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    approx = 1/norm_c if (calc_min and not use_inverse and norm_c_mode=='max_abs') else np.dot(B.T,np.dot(A,B))/np.linalg.norm(B)\n",
        "    if calc_min and use_inverse: approx=1./approx\n",
        "    approx += Sigma\n",
        "    end_time = time.time()\n",
        "\n",
        "    logger.success(method_name+' = '+ str(approx)+'; time = '+str(end_time-start_time)+ \" seconds.\")\n",
        "\n",
        "\n",
        "\n",
        "    w, v = np.linalg.eig(A_orginal)\n",
        "    w=np.sort(w)\n",
        "    diff = (w[0] if calc_min else w[-1])- approx\n",
        "    logger.trace('exact eigenvalue='+(str(w[0]) if calc_min else str(w[-1])))\n",
        "    logger.trace('Residual = '+ str(diff))\n",
        "    if output_approx_instead_of_residuals: return approx,B,end_time-start_time,j,residuals,approx_egien_values\n",
        "    else:\n",
        "        return approx,B,end_time-start_time,j,residuals\n",
        "\n",
        "\n",
        "def davidson_1(A,v0=None,tol=1e-10,maxiter=1000):\n",
        "    '''\n",
        "    The Davidson's algorithm.\n",
        "\n",
        "    Parameters:\n",
        "        :A: matrix, the input matrix.\n",
        "        :v0: 2D array, the initial subspace.\n",
        "        :tol: float, the tolerence.\n",
        "        :maxiter: int, the maximum number of iteration times.\n",
        "\n",
        "    Return:\n",
        "        tuple of (e,v), e is the eigenvalues and v the eigenvector e is the eigenvalues and v the eigenvectors.\n",
        "    '''\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    N=A.shape[0]\n",
        "    # A=A.tocsr()\n",
        "    DA_diag=A.diagonal()\n",
        "    if v0 is None:\n",
        "        v0=np.random.random((N,1))\n",
        "    elif np.ndim(v0)==1:\n",
        "        v0=v0[:,np.newaxis]\n",
        "    v0=mt.normalize(v0)\n",
        "    Av=A.dot(v0)\n",
        "    AV=Av\n",
        "    V=v0\n",
        "    #initialise projected matrix.\n",
        "    G=v0.T.conj().dot(Av)\n",
        "    for i in range(maxiter):\n",
        "        ei,vi=np.linalg.eig(G)\n",
        "        #compute largest Ritz value theta, and Ritz vector u.\n",
        "        imax=np.argmax(ei)\n",
        "        theta,u=ei[imax],V.dot(vi[:,imax:imax+1])\n",
        "        #get the residual\n",
        "        r=AV.dot(vi[:,imax:imax+1])-theta*u\n",
        "        if norm(r)<tol:\n",
        "            break\n",
        "\n",
        "        if(i%20==0):logger.trace(str(i)+' ||r|| = '+ str(norm(r))+', eigen value = '+str(theta))\n",
        "        #compute the correction vector z\n",
        "        z=-1./(DA_diag-theta)[:,np.newaxis]*r\n",
        "        z=mt.mgs(z,V)\n",
        "        z=mt.normalize(z)\n",
        "\n",
        "        Av=A.dot(z)\n",
        "        #add z to search space.\n",
        "        AV=np.concatenate([AV,Av],axis=1)\n",
        "        #update G, G=UAU.H\n",
        "        gg=[[G,V.T.conj().dot(Av)],[Av.T.conj().dot(V),Av.T.conj().dot(z)]]\n",
        "        G=np.bmat([[G,V.T.conj().dot(Av)],[Av.T.conj().dot(V),Av.T.conj().dot(z)]])\n",
        "        V=np.concatenate([V,z],axis=1)\n",
        "    end_time = time.time()\n",
        "\n",
        "       # End of block Davidson. Print results.\n",
        "\n",
        "    logger.success(\"davidson_1 = \"+ str(theta)+\"; time = \"+\n",
        "        str(end_time - start_time)+ \" seconds.\")\n",
        "\n",
        "\n",
        "    return theta,u\n",
        "def davidson_2(A,k=None,n_eigen=1,tol=1e-10,maxiter=1000):\n",
        "    ''' Block Davidson, Joshua Goings (2013)\n",
        "\n",
        "    Block Davidson method for finding the first few\n",
        "\tlowest eigenvalues of a large, diagonally dominant,\n",
        "    sparse Hermitian matrix (e.g. Hamiltonian)\n",
        "'''\n",
        "    n=A.shape[0]\n",
        "    maxiter = n//2\t\t\t\t# Maximum number of iterations\n",
        "\n",
        "    if k is None:k=2*n_eigen\n",
        "    t = np.eye(n,k)\t\t\t# set of k unit vectors as guess\n",
        "    V = np.zeros((n,n))\t\t# array of zeros to hold guess vec\n",
        "    I = np.eye(n)\t\t\t# identity matrix same dimen as A\n",
        "    residuals=[]\n",
        "    # Begin block Davidson routine\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for maxiter in range(k,maxiter,k):\n",
        "        if maxiter <= k:\n",
        "            for j in range(0,k):\n",
        "                V[:,j] = t[:,j]/np.linalg.norm(t[:,j])\n",
        "            theta_old = 1\n",
        "        elif maxiter > k:\n",
        "            theta_old = theta[:n_eigen]\n",
        "        V[:,:maxiter],R = np.linalg.qr(V[:,:maxiter])\n",
        "        T = np.dot(V[:,:maxiter].T,np.dot(A,V[:,:maxiter]))\n",
        "        THETA,S = np.linalg.eig(T)\n",
        "        idx = THETA.argsort()\n",
        "        theta = THETA[idx]\n",
        "        s = S[:,idx]\n",
        "        for j in range(0,k):\n",
        "            w = np.dot((A - theta[j]*I),np.dot(V[:,:maxiter],s[:,j]))\n",
        "            q = w/(theta[j]-A[j,j])\n",
        "            V[:,(maxiter+j)] = q\n",
        "        norm = np.linalg.norm(theta[:n_eigen] - theta_old)\n",
        "        residuals.append(norm)\n",
        "        if norm < tol:\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # End of block Davidson. Print results.\n",
        "\n",
        "    logger.success(\"davidson_2 = \"+ str(theta[:n_eigen])+\"; time = \"+\n",
        "       str(end_time - start_time)+\" seconds.\")\n",
        "    return theta[:n_eigen], s[:n_eigen],residuals\n",
        "def davidson_3(A,k=None,n_eigen=1,tol=1e-10,maxiter=1000):\n",
        "    '''\n",
        "    The Block Davidson method ca be used to solve for a number of the lowest or highest few Eigenvalues of a symmetric matrix.\n",
        "    https://github.com/sreeganb/davidson_algorithm/\n",
        "    Important: Input matrix must be symmetric\n",
        "    '''\n",
        "    #-------------------------------------------------------------------------------\n",
        "# Attempt at Block Davidson algorithm\n",
        "# Sree Ganesh (sreeuci@gmail.com)\n",
        "# Summer 2017\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "    n=A.shape[0]\n",
        "    # Setup the subspace trial vectors\n",
        "    if k is None:k=2*n_eigen\n",
        "    # logger.trace('No. of start vectors:'+str(k))\n",
        "    # logger.trace('No. of desired Eigenvalues:'+str(n_eigen))\n",
        "    t = np.eye(n,k) # initial trial vectors\n",
        "    v = np.zeros((n,n)) # holder for trial vectors as iterations progress\n",
        "    I = np.eye(n) # n*n identity matrix\n",
        "    ritz = np.zeros((n,n))\n",
        "    f = np.zeros((n,n))\n",
        "    residuals=[]\n",
        "    #-------------------------------------------------------------------------------\n",
        "    # Begin iterations\n",
        "    #-------------------------------------------------------------------------------\n",
        "    start = time.time()\n",
        "    iter = 0\n",
        "    for maxiter in range(k,maxiter,k):\n",
        "        iter = iter + 1\n",
        "        # logger.trace(\"Iteration no:\"+ str(iter))\n",
        "        if iter==1:  # for first iteration add normalized guess vectors to matrix v\n",
        "            for eigen_values in range(maxiter):\n",
        "                v[:,eigen_values] = t[:,eigen_values]/(np.linalg.norm(t[:,eigen_values]))\n",
        "        # Matrix-vector products, form the projected Hamiltonian in the subspace\n",
        "        T = np.linalg.multi_dot([v[:,:maxiter].T,A,v[:,:maxiter]]) # selects fastest evaluation order\n",
        "        w, vects = np.linalg.eig(T) # Diagonalize the subspace Hamiltonian\n",
        "        j = 0\n",
        "        s = w.argsort()\n",
        "        ss = w[s]\n",
        "        #***************************************************************************\n",
        "        # For each eigenvector of T build a Ritz vector, precondition it and check\n",
        "        # if the norm is greater than a set threshold.\n",
        "        #***************************************************************************\n",
        "        for i in range(maxiter): #for each new eigenvector of T\n",
        "            f = np.diag(1./ np.diag((np.diag(np.diag(A)) - w[i]*I)))\n",
        "    #        logger.trace(f)\n",
        "            ritz[:,i] = np.dot(f,np.linalg.multi_dot([(A-w[i]*I),v[:,:maxiter],vects[:,i]]))\n",
        "            if np.linalg.norm(ritz[:,i]) > 1e-7 :\n",
        "                ritz[:,i] = ritz[:,i]/(np.linalg.norm(ritz[:,i]))\n",
        "                v[:,maxiter+j] = ritz[:,i]\n",
        "                j = j + 1\n",
        "        q, r = np.linalg.qr(v[:,:maxiter+j-1])\n",
        "        for kk in range(maxiter+j-1):\n",
        "            v[:,kk] = q[:,kk]\n",
        "        # for i in range(n_eigen):\n",
        "        #     logger.trace(ss[i])\n",
        "        if iter==1:\n",
        "            check_old = ss[:n_eigen]\n",
        "            check_new = 1\n",
        "        elif iter==2:\n",
        "            check_new = ss[:n_eigen]\n",
        "        else:\n",
        "            check_old = check_new\n",
        "            check_new = ss[:n_eigen]\n",
        "        check = np.linalg.norm(check_new - check_old)\n",
        "        residuals.append(check)\n",
        "        if check < tol:\n",
        "            logger.info('Block Davidson converged at iteration number = '+str(iter))\n",
        "            break\n",
        "    end = time.time()\n",
        "    logger.success(\"davidson_3 = \"+ str(ss[:n_eigen])+\"; time = \"+str(end-start)+\" seconds.\")\n",
        "\n",
        "    return ss[:n_eigen],v[:n_eigen],residuals\n",
        "def get_initial_guess(A,n_eigen):\n",
        "    nrows, ncols = A.shape\n",
        "    d = np.diag(A)\n",
        "    index = np.argsort(d)\n",
        "    guess = np.zeros((nrows,n_eigen))\n",
        "    for i in range(n_eigen):\n",
        "        guess[index[i],i] = 1\n",
        "\n",
        "    return guess\n",
        "def jacobi_correction(uj,A,thetaj):\n",
        "    I = np.eye(A.shape[0])\n",
        "    Pj = I-np.dot(uj,uj.T)\n",
        "    rj = np.dot((A - thetaj*I),uj)\n",
        "\n",
        "    w = np.dot(Pj,np.dot((A-thetaj*I),Pj))\n",
        "    return np.linalg.solve(w,rj)\n",
        "def davidson_4(A, n_eigen=1, tol=1E-6, maxiter = 1000, jacobi=False,non_hermitian=False,hamiltonian=False,output_approx_instead_of_residuals=False):\n",
        "    \"\"\"Davidosn solver for eigenvalue problem\n",
        "    https://github.com/NLESC-JCER/DavidsonPython/tree/master\n",
        "\n",
        "    Args :\n",
        "        A (numpy matrix) : the matrix to diagonalize\n",
        "        n_eigen (int)     : the number of eigenvalue requied\n",
        "        tol (float)      : the rpecision required\n",
        "        maxiter (int)    : the maximum number of iteration\n",
        "        jacobi (bool)    : do the jacobi correction\n",
        "    Returns :\n",
        "        eigenvalues (array) : lowest eigenvalues\n",
        "        eigenvectors (numpy.array) : eigenvectors\n",
        "    \"\"\"\n",
        "    n = A.shape[0]\n",
        "    k = 2*n_eigen            # number of initial guess vectors\n",
        "    V = np.eye(n,k)         # set of k unit vectors as guess\n",
        "    I = np.eye(n)           # identity matrix same dimen as A\n",
        "    Adiag = np.diag(A)\n",
        "    residuals=[]\n",
        "    approx_egien_values=[]\n",
        "    start_time = time.time()\n",
        "\n",
        "    V = get_initial_guess(A,k)\n",
        "\n",
        "    # print('\\n'+'='*20)\n",
        "    # logger.trace(\"= Davidson Solver \")\n",
        "    # print('='*20)\n",
        "\n",
        "    #invA = np.linalg.inv(A)\n",
        "    #inv_approx_0 = 2*I - A\n",
        "    #invA2 = np.dot(invA,invA)\n",
        "    #invA3 = np.dot(invA2,invA)\n",
        "\n",
        "    norm = np.zeros(k if hamiltonian else n_eigen)\n",
        "\n",
        "    # Begin block Davidson routine\n",
        "    # logger.trace(\"iter size norm\"+str(tol))\n",
        "    i=0\n",
        "    while i<maxiter:\n",
        "\n",
        "        # QR of V t oorthonormalize the V matrix\n",
        "        # this uses GrahmShmidtd in the back\n",
        "        V,R = np.linalg.qr(V)\n",
        "\n",
        "        # form the projected matrix\n",
        "\n",
        "        T = np.dot(V.conj().T if hamiltonian or non_hermitian else V.T,np.dot(A,V))\n",
        "\n",
        "\n",
        "\n",
        "        # Diagonalize the projected matrix\n",
        "        theta,s = np.linalg.eigh(T)\n",
        "\n",
        "        if hamiltonian or non_hermitian:\n",
        "            # print(np.diag(T))\n",
        "            # organize the eigenpairs\n",
        "            index = np.argsort(theta.real)\n",
        "            theta  = theta[index]\n",
        "            s = s[:,index]\n",
        "\n",
        "        # Ritz eigenvector\n",
        "        q = np.dot(V,s)\n",
        "\n",
        "        # compute the residual append append it to the\n",
        "        # set of eigenvectors\n",
        "        if hamiltonian:\n",
        "            ind0 = np.where(theta>0, theta, np.inf).argmin()\n",
        "\n",
        "        for _j in range(k if hamiltonian else n_eigen):\n",
        "            j = ind0+_j-int(0.25*k) if hamiltonian else +_j\n",
        "\n",
        "            # residue vetor\n",
        "            res = np.dot((A - theta[j]*I),q[:,j])\n",
        "            norm[_j] = np.linalg.norm(res)\n",
        "\n",
        "            # correction vector\n",
        "            if jacobi:\n",
        "            \tdelta = jacobi_correction(q[:,j],A,theta[j])\n",
        "            else:\n",
        "                # print(res)\n",
        "                # print(theta[j])\n",
        "                delta = res / (theta[j]-Adiag+1E-16)\n",
        "                #C = inv_approx_0 + theta[j]*I\n",
        "                #delta = -np.dot(C,res)\n",
        "            # print(delta)\n",
        "\n",
        "            if(np.all(delta!=0)):delta /= np.linalg.norm(delta)\n",
        "\n",
        "            # expand the basis\n",
        "            V = np.hstack((V,delta.reshape(-1,1)))\n",
        "\n",
        "        # comute the norm to see if eigenvalue converge\n",
        "        # logger.trace(str(i)+\" \"+str(V.shape[1])+\" \"+ str(np.max(norm)))\n",
        "        residuals.append(np.max(norm))\n",
        "        if output_approx_instead_of_residuals:\n",
        "            if not hamiltonian: ind0=0\n",
        "            approx_egien_values.append(theta[ind0:ind0+n_eigen])\n",
        "        i+=1\n",
        "\n",
        "        if np.all(norm < tol):\n",
        "            logger.info(\"Davidson_4 has converged in iteration number = \"+str(i))\n",
        "            break\n",
        "    end_time = time.time()\n",
        "    if not hamiltonian: ind0=0\n",
        "    logger.success(\"Davidson_4 = \"+ str(theta[ind0:n_eigen+ind0])+\"; time = \"+str(end_time-start_time)+\" seconds.\")\n",
        "\n",
        "    if output_approx_instead_of_residuals:\n",
        "        return theta[ind0:ind0+n_eigen], q[:,ind0:ind0+n_eigen],end_time-start_time,i,residuals,approx_egien_values\n",
        "    else:\n",
        "        return theta[ind0:ind0+n_eigen], q[:,ind0:ind0+n_eigen],end_time-start_time,i,residuals\n",
        "def numpy_eigen(A,l,u):\n",
        "      # Begin Numpy diagonalization of A\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    E,Vec = np.linalg.eig(A)\n",
        "    idx=np.argsort(E)\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "    E = E[idx]\n",
        "    Vec=Vec[idx]\n",
        "\n",
        "    # End of Numpy diagonalization. Print results.\n",
        "\n",
        "    logger.success(\"numpy = \"+ str(E[l:u])+\"; time = \"+\n",
        "       str(end_time - start_time) + \" seconds\")\n",
        "    return E[l:u],Vec[l:u],end_time - start_time,0,np.zeros((A.shape[0], abs(l-u))),E[l:u]\n",
        "\n",
        "def main():\n",
        "    A=mt.symmetric_sparse(100)\n",
        "\n",
        "    nr=numpy_eigen(A,99,100)\n",
        "    print(nr[1])\n",
        "    r=subspace_iteration_1(A,k=1,maxiter=100)\n",
        "    print(r[1].T)\n",
        "    print(nr[1]-r[1].T)\n",
        "if __name__=='__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rayleigh_quotient_iteration(A, tol=1e-10, rcoeff=0, B=None):\n",
        "    n=A.shape[0]\n",
        "    residuals=[]\n",
        "\n",
        "    if B is None:\n",
        "        B=np.random.rand(n)\n",
        "    B = B / la.norm(B)\n",
        "\n",
        "    # the solve function in scipy.linalg solves a linear system\n",
        "    start_time=time.time()\n",
        "    try:\n",
        "        C = la.solve(A - rcoeff * np.eye(n), B)\n",
        "\n",
        "    except la.LinAlgError as exc:\n",
        "        # logger.exception(exc)\n",
        "        logger.warning(\"la.solve failed. Trying to use la_factor and la_solve.\")\n",
        "        try:\n",
        "            LU, piv = lu_factor(A - rcoeff * np.eye(n))\n",
        "            C=lu_solve((LU,piv),B)\n",
        "        except np.linalg.LinAlgError as exc:\n",
        "            # logger.exception(exc)\n",
        "            logger.warning(\"lu_solve and lu_factor failed. please try use_inverse\")\n",
        "            raise exc\n",
        "\n",
        "\n",
        "\n",
        "    lambda_ = C.T @ B\n",
        "    rcoeff = rcoeff + 1 / lambda_\n",
        "    err = la.norm(C - lambda_ * B) / la.norm(C)\n",
        "    residuals.append(err)\n",
        "    j=0\n",
        "    while err > tol:\n",
        "        j+=1\n",
        "        B = C / la.norm(C)\n",
        "        try:\n",
        "            C = la.solve(A - rcoeff * np.eye(n), B)\n",
        "\n",
        "        except la.LinAlgError as exc:\n",
        "            # logger.exception(exc)\n",
        "            logger.warning(\"la.solve failed. Trying to use la_factor and la_solve.\")\n",
        "            try:\n",
        "                LU, piv = lu_factor(A - rcoeff * np.eye(n))\n",
        "                C=lu_solve((LU,piv),B)\n",
        "            except np.linalg.LinAlgError as exc:\n",
        "                # logger.exception(exc)\n",
        "                logger.warning(\"lu_solve and lu_factor failed. please try use_inverse\")\n",
        "                raise exc\n",
        "        lambda_ = C.T @ B\n",
        "        rcoeff = rcoeff + 1 / lambda_\n",
        "        err = la.norm(C - lambda_ * B) / la.norm(C)\n",
        "\n",
        "    logger.info('Rayleigh Quotient Iteration converged at iteration number = '+ str(j))\n",
        "    # approx=np.dot(B.T,np.dot(A,B))/np.linalg.norm(B)\n",
        "    end_time=time.time()\n",
        "\n",
        "    # logger.success(' Reigh iteration '+ str(approx)+'; time = '+str(end_time-start_time)+ \" seconds.\")\n",
        "    logger.success('Rayleigh Quotient Iteration = '+ str(rcoeff)+'; time = '+str(end_time-start_time)+ \" seconds.\")\n",
        "\n",
        "    return rcoeff,B,residuals\n",
        "\n",
        "def power_iteration(A,tol=1e-10,maxiter=1000,use_rayleigh=False,calc_min=False,use_inverse=True,Sigma=0,norm_c_mode='2',output_approx_instead_of_residuals=False):\n",
        "    if calc_min:\n",
        "        method_name='Inverse iteration: use_inverse = {}, use_rayleigh = {}, norm_c_mode = {}'.format(use_inverse, use_rayleigh, norm_c_mode)\n",
        "    else:\n",
        "        method_name='Power iteration: use_inverse = {}, use_rayleigh = {}, norm_c_mode = {}'.format(use_inverse, use_rayleigh, norm_c_mode)\n",
        "    n=A.shape[0]\n",
        "    residuals=[]\n",
        "    approx_egien_values=[]\n",
        "    A_orginal=A.copy()\n",
        "    start_time = time.time()\n",
        "    A_Sigma=A_orginal-Sigma*np.eye(n)\n",
        "    A=A_Sigma.copy()\n",
        "    # if not calc_min and use_inverse:\n",
        "    #     logger.warning('Ignoring use_inverse. Use_inverse is an option when calc_min is set to True.')\n",
        "\n",
        "    if calc_min:\n",
        "        if use_inverse:\n",
        "            try :\n",
        "                A=np.linalg.inv(A)\n",
        "            except np.linalg.LinAlgError as exc:\n",
        "                # logger.exception(exc)\n",
        "                logger.warning(\"Matrix is singuar. Trying to use psudo inverse of A. Also you can turn off use_inverse flag for using lu_factor and lu_solver to solve the linear system. \")\n",
        "                A=np.linalg.pinv(A)\n",
        "        else:\n",
        "            if not use_rayleigh:\n",
        "\n",
        "                     LU,piv=lu_factor(A)\n",
        "    else:\n",
        "        if use_rayleigh:\n",
        "            logger.warning('calc_min is off. use_rayleigh is ignored.')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Build a random trial vector\n",
        "    B=np.random.rand(n)\n",
        "    B=B/la.norm(B)\n",
        "    j=0\n",
        "    rcoeff=0\n",
        "    norm_mat=np.zeros(2)\n",
        "    while j<maxiter:\n",
        "        if calc_min:\n",
        "            if use_rayleigh:\n",
        "\n",
        "                rcoeff = np.dot(B.T,np.dot(A,B))/np.linalg.norm(B)\n",
        "            if not use_inverse:\n",
        "                if use_rayleigh:\n",
        "\n",
        "                    try:\n",
        "                        C=la.solve(A_Sigma-rcoeff*np.eye(n),B)\n",
        "\n",
        "                    except (la.LinAlgError, la.LinAlgWarning) as exc:\n",
        "                        # logger.exception(exc)\n",
        "                        logger.warning(\"la.solve failed. Trying to use la_factor and la_solve.\")\n",
        "                        try:\n",
        "                            LU, piv = la.lu_factor(A_Sigma-rcoeff*np.eye(n))\n",
        "                            C=la.lu_solve((LU,piv),B)\n",
        "                            if(np.any(C==None) or np.any(C==np.inf)):\n",
        "                                logger.warning(\"lu_solve and lu_factor failed. please try use_inverse\")\n",
        "                                A_new=A_Sigma-rcoeff*np.eye(n)\n",
        "                                try :\n",
        "                                    A_new=np.linalg.inv(A_new)\n",
        "                                except np.linalg.LinAlgError as exc:\n",
        "\n",
        "                                    # logger.exception(exc)\n",
        "                                    logger.warning(\"Matrix is singuar. Trying to use psudo inverse of A_new. Also you can turn off use_inverse flag for using lu_factor and lu_solver to solve the linear system. \")\n",
        "                                    A_new=np.linalg.pinv(A_new)\n",
        "                                C =  np.dot(A_new,B)  if use_rayleigh else np.dot(A,B)\n",
        "\n",
        "                        except (la.LinAlgError, la.LinAlgWarning)  as exc:\n",
        "                            # logger.exception(exc)\n",
        "                            logger.warning(\"lu_solve and lu_factor failed. please try use_inverse\")\n",
        "                            # raise exc\n",
        "                else:\n",
        "                    C=lu_solve((LU,piv),B)\n",
        "                idx=np.argmax(np.abs(C))\n",
        "            else:\n",
        "                if use_rayleigh:\n",
        "                    A_new=A_Sigma-rcoeff*np.eye(n)\n",
        "                    try :\n",
        "                        A_new=np.linalg.inv(A_new)\n",
        "                    except np.linalg.LinAlgError as exc:\n",
        "\n",
        "                        # logger.exception(exc)\n",
        "                        logger.warning(\"Matrix is singuar. Trying to use psudo inverse of A_new. Also you can turn off use_inverse flag for using lu_factor and lu_solver to solve the linear system. \")\n",
        "                        A_new=np.linalg.pinv(A_new)\n",
        "\n",
        "                C =  np.dot(A_new,B)  if use_rayleigh else np.dot(A,B)\n",
        "        else:\n",
        "            C = np.dot(A,B)\n",
        "\n",
        "\n",
        "        norm_c = C[idx] if ( not use_inverse and calc_min and norm_c_mode=='max_abs') else np.linalg.norm(C)\n",
        "        B = C/(norm_c)\n",
        "        j=j+1\n",
        "        # print(j)\n",
        "        if j==1:\n",
        "            logger.trace('just the first iteration, give me a break')\n",
        "            norm_mat[0]=norm_c\n",
        "        else:\n",
        "            norm_mat[1] = norm_mat[0]\n",
        "            norm_mat[0] = norm_c\n",
        "            if( calc_min and use_rayleigh and not use_inverse):\n",
        "                diff=la.norm(C-(C.T@B)*B)\n",
        "            else:\n",
        "                diff = abs(norm_mat[1] - norm_mat[0])\n",
        "            residuals.append(diff)\n",
        "            if output_approx_instead_of_residuals:\n",
        "                approx = 1/norm_c if (calc_min and not use_inverse and norm_c_mode=='max_abs') else np.dot(B.T,np.dot(A,B))/np.linalg.norm(B)\n",
        "                if calc_min and use_inverse: approx=1./approx\n",
        "                approx += Sigma\n",
        "                approx_egien_values.append(approx)\n",
        "            if diff < tol:\n",
        "                logger.info('Power iteration converged at iteration number = '+ str(j))\n",
        "                break\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    approx = 1/norm_c if (calc_min and not use_inverse and norm_c_mode=='max_abs') else np.dot(B.T,np.dot(A,B))/np.linalg.norm(B)\n",
        "    if calc_min and use_inverse: approx=1./approx\n",
        "    approx += Sigma\n",
        "    end_time = time.time()\n",
        "    logger.success(method_name+' = '+ str(approx)+'; time = '+str(end_time-start_time)+ \" seconds.\")\n",
        "    w, v = np.linalg.eig(A_orginal)\n",
        "    w=np.sort(w)\n",
        "    diff = (w[0] if calc_min else w[-1])- approx\n",
        "    logger.trace('exact eigenvalue='+(str(w[0]) if calc_min else str(w[-1])))\n",
        "    logger.trace('Residual = '+ str(diff))\n",
        "    if output_approx_instead_of_residuals: return approx,B,end_time-start_time,j,residuals,approx_egien_values\n",
        "    else:\n",
        "        return approx,B,end_time-start_time,j,residuals\n"
      ],
      "metadata": {
        "id": "4qlc61pAKdsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import lu_factor, lu_solve, qr\n",
        "\n",
        "def power_iteration(A, tol=1e-10, maxiter=1000):\n",
        "    \"\"\"Power Iteration Method to find the dominant eigenvalue and eigenvector.\"\"\"\n",
        "    n = A.shape[0]\n",
        "    v = np.random.rand(n)\n",
        "    v /= np.linalg.norm(v)\n",
        "\n",
        "    for _ in range(maxiter):\n",
        "        w = np.dot(A, v)\n",
        "        v_next = w / np.linalg.norm(w)\n",
        "        if np.linalg.norm(v_next - v) < tol:\n",
        "            break\n",
        "        v = v_next\n",
        "\n",
        "    eigenvalue = np.dot(v.T, np.dot(A, v))\n",
        "    return eigenvalue, v\n",
        "\n",
        "def inverse_iteration(A, tol=1e-10, maxiter=1000):\n",
        "    \"\"\"Inverse Iteration Method to find the smallest eigenvalue and eigenvector.\"\"\"\n",
        "    n = A.shape[0]\n",
        "    v = np.random.rand(n)\n",
        "    v /= np.linalg.norm(v)\n",
        "\n",
        "    for _ in range(maxiter):\n",
        "        w = np.linalg.solve(A, v)\n",
        "        v_next = w / np.linalg.norm(w)\n",
        "        if np.linalg.norm(v_next - v) < tol:\n",
        "            break\n",
        "        v = v_next\n",
        "\n",
        "    eigenvalue = np.dot(v.T, np.dot(A, v))\n",
        "    return eigenvalue, v\n",
        "\n",
        "def shifted_inverse_iteration(A, shift, tol=1e-10, maxiter=1000):\n",
        "    \"\"\"Shifted Inverse Iteration to compute eigenvalues near a given shift.\"\"\"\n",
        "    n = A.shape[0]\n",
        "    v = np.random.rand(n)\n",
        "    v /= np.linalg.norm(v)\n",
        "    shifted_A = A - shift * np.eye(n)\n",
        "\n",
        "    for _ in range(maxiter):\n",
        "        w = np.linalg.solve(shifted_A, v)\n",
        "        v_next = w / np.linalg.norm(w)\n",
        "        if np.linalg.norm(v_next - v) < tol:\n",
        "            break\n",
        "        v = v_next\n",
        "\n",
        "    eigenvalue = np.dot(v.T, np.dot(A, v))\n",
        "    return eigenvalue, v\n",
        "\n",
        "def rayleigh_quotient_iteration(A, tol=1e-10, maxiter=1000):\n",
        "    \"\"\"Rayleigh Quotient Iteration with regularization to avoid singularity.\"\"\"\n",
        "    n = A.shape[0]\n",
        "    v = np.random.rand(n)\n",
        "    v /= np.linalg.norm(v)\n",
        "    lambda_approx = np.dot(v.T, np.dot(A, v))\n",
        "\n",
        "    for _ in range(maxiter):\n",
        "        shifted_A = A - lambda_approx * np.eye(n)\n",
        "\n",
        "        try:\n",
        "            # Solve for the new eigenvector\n",
        "            w = np.linalg.solve(shifted_A, v)\n",
        "        except np.linalg.LinAlgError:\n",
        "            # Handle singular matrix case using pseudo-inverse\n",
        "            w = np.dot(np.linalg.pinv(shifted_A), v)\n",
        "\n",
        "        v_next = w / np.linalg.norm(w)\n",
        "        lambda_next = np.dot(v_next.T, np.dot(A, v_next))\n",
        "\n",
        "        if np.linalg.norm(v_next - v) < tol:\n",
        "            break\n",
        "\n",
        "        v, lambda_approx = v_next, lambda_next\n",
        "\n",
        "    return lambda_approx, v\n",
        "\n",
        "\n",
        "def simultaneous_iteration(A, tol=1e-10, maxiter=1000):\n",
        "    \"\"\"Simultaneous Iteration for computing all eigenvalues and eigenvectors.\"\"\"\n",
        "    n = A.shape[0]\n",
        "    V = np.random.rand(n, n)\n",
        "    Q, _ = np.linalg.qr(V)  # Orthonormalize initial matrix\n",
        "\n",
        "    for _ in range(maxiter):\n",
        "        W = np.dot(A, Q)\n",
        "        Q_next, R = np.linalg.qr(W)\n",
        "        if np.linalg.norm(Q_next - Q) < tol:\n",
        "            break\n",
        "        Q = Q_next\n",
        "\n",
        "    eigenvalues = np.diag(np.dot(Q.T, np.dot(A, Q)))\n",
        "    return eigenvalues, Q\n",
        "\n",
        "def qr_method(A, tol=1e-10, maxiter=1000):\n",
        "    \"\"\"QR Method for computing all eigenvalues.\"\"\"\n",
        "    Ak = A.copy()\n",
        "    for _ in range(maxiter):\n",
        "        Q, R = qr(Ak)\n",
        "        Ak = np.dot(R, Q)\n",
        "        off_diagonal = np.sqrt(np.sum(np.tril(Ak, -1)**2))\n",
        "        if off_diagonal < tol:\n",
        "            break\n",
        "\n",
        "    eigenvalues = np.diag(Ak)\n",
        "    return eigenvalues\n",
        "\n",
        "# Inbuilt NumPy Eigenvalue Calculation\n",
        "def numpy_eig(A):\n",
        "    \"\"\"NumPy's inbuilt eigenvalue and eigenvector calculation.\"\"\"\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "    return eigenvalues, eigenvectors\n",
        "\n",
        "def main():\n",
        "    A = np.array([[6, 5], [5, 7]], dtype=float)\n",
        "\n",
        "    print(\"\\nPower Iteration:\")\n",
        "    eigval, eigvec = power_iteration(A)\n",
        "    print(\"Eigenvalue:\", eigval, \"\\nEigenvector:\", eigvec)\n",
        "\n",
        "    print(\"\\nInverse Iteration:\")\n",
        "    eigval, eigvec = inverse_iteration(A)\n",
        "    print(\"Eigenvalue:\", eigval, \"\\nEigenvector:\", eigvec)\n",
        "\n",
        "    print(\"\\nShifted Inverse Iteration:\")\n",
        "    shift = 6\n",
        "    eigval, eigvec = shifted_inverse_iteration(A, shift)\n",
        "    print(\"Eigenvalue:\", eigval, \"\\nEigenvector:\", eigvec)\n",
        "\n",
        "    print(\"\\nRayleigh Quotient Iteration:\")\n",
        "    eigval, eigvec = rayleigh_quotient_iteration(A)\n",
        "    print(\"Eigenvalue:\", eigval, \"\\nEigenvector:\", eigvec)\n",
        "\n",
        "    print(\"\\nSimultaneous Iteration:\")\n",
        "    eigvals, eigvecs = simultaneous_iteration(A)\n",
        "    print(\"Eigenvalues:\", eigvals, \"\\nEigenvectors:\\n\", eigvecs)\n",
        "\n",
        "    print(\"\\nQR Method:\")\n",
        "    eigvals = qr_method(A)\n",
        "    print(\"Eigenvalues:\", eigvals)\n",
        "\n",
        "    # Inbuilt NumPy Method for comparison\n",
        "    print(\"\\nNumPy Inbuilt Eigenvalue Computation:\")\n",
        "    eigvals_numpy, eigvecs_numpy = numpy_eig(A)\n",
        "    print(\"Eigenvalues:\", eigvals_numpy)\n",
        "    print(\"Eigenvectors:\\n\", eigvecs_numpy)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "oqiub3hINs6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import qr\n",
        "\n",
        "# Power Iteration\n",
        "def power_iteration_with_residuals(A, tol=1e-10, maxiter=1000):\n",
        "    n = A.shape[0]\n",
        "    v = np.random.rand(n)\n",
        "    v /= np.linalg.norm(v)\n",
        "    approximations = []\n",
        "\n",
        "    for _ in range(maxiter):\n",
        "        w = np.dot(A, v)\n",
        "        v_next = w / np.linalg.norm(w)\n",
        "        approximations.append(np.dot(v.T, np.dot(A, v)))\n",
        "        if np.linalg.norm(v_next - v) < tol:\n",
        "            break\n",
        "        v = v_next\n",
        "\n",
        "    return approximations\n",
        "\n",
        "# Inverse Iteration\n",
        "def inverse_iteration_with_residuals(A, tol=1e-10, maxiter=1000):\n",
        "    n = A.shape[0]\n",
        "    v = np.random.rand(n)\n",
        "    v /= np.linalg.norm(v)\n",
        "    approximations = []\n",
        "\n",
        "    for _ in range(maxiter):\n",
        "        w = np.linalg.solve(A, v)\n",
        "        v_next = w / np.linalg.norm(w)\n",
        "        approximations.append(np.dot(v.T, np.dot(A, v)))\n",
        "        if np.linalg.norm(v_next - v) < tol:\n",
        "            break\n",
        "        v = v_next\n",
        "\n",
        "    return approximations\n",
        "\n",
        "# Shifted Inverse Iteration\n",
        "def shifted_inverse_iteration_with_residuals(A, shift, tol=1e-10, maxiter=1000):\n",
        "    n = A.shape[0]\n",
        "    v = np.random.rand(n)\n",
        "    v /= np.linalg.norm(v)\n",
        "    shifted_A = A - shift * np.eye(n)\n",
        "    approximations = []\n",
        "\n",
        "    for _ in range(maxiter):\n",
        "        w = np.linalg.solve(shifted_A, v)\n",
        "        v_next = w / np.linalg.norm(w)\n",
        "        approximations.append(np.dot(v.T, np.dot(A, v)))\n",
        "        if np.linalg.norm(v_next - v) < tol:\n",
        "            break\n",
        "        v = v_next\n",
        "\n",
        "    return approximations\n",
        "\n",
        "# Rayleigh Quotient Iteration\n",
        "def rayleigh_quotient_iteration_with_residuals(A, tol=1e-10, maxiter=1000):\n",
        "    n = A.shape[0]\n",
        "    v = np.random.rand(n)\n",
        "    v /= np.linalg.norm(v)\n",
        "    lambda_approx = np.dot(v.T, np.dot(A, v))\n",
        "    approximations = [lambda_approx]\n",
        "\n",
        "    for _ in range(maxiter):\n",
        "        shifted_A = A - lambda_approx * np.eye(n)\n",
        "\n",
        "        try:\n",
        "            w = np.linalg.solve(shifted_A, v)\n",
        "        except np.linalg.LinAlgError:\n",
        "            w = np.dot(np.linalg.pinv(shifted_A), v)\n",
        "\n",
        "        v_next = w / np.linalg.norm(w)\n",
        "        lambda_next = np.dot(v_next.T, np.dot(A, v_next))\n",
        "        approximations.append(lambda_next)\n",
        "\n",
        "        if abs(lambda_next - lambda_approx) < tol:\n",
        "            break\n",
        "\n",
        "        v, lambda_approx = v_next, lambda_next\n",
        "\n",
        "    return approximations\n",
        "\n",
        "# Plot Residuals\n",
        "def plot_residuals(A):\n",
        "    actual_eigenvalues, _ = np.linalg.eig(A)\n",
        "    actual_max = max(actual_eigenvalues)\n",
        "    actual_min = min(actual_eigenvalues)\n",
        "\n",
        "    # Run algorithms\n",
        "    power_residuals = [abs(approx - actual_max) for approx in power_iteration_with_residuals(A)]\n",
        "    inverse_residuals = [abs(approx - actual_min) for approx in inverse_iteration_with_residuals(A)]\n",
        "    shifted_residuals = [abs(approx - actual_min) for approx in shifted_inverse_iteration_with_residuals(A, shift=6)]\n",
        "    rayleigh_residuals = [abs(approx - actual_max) for approx in rayleigh_quotient_iteration_with_residuals(A)]\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.semilogy(power_residuals, label=\"Power Iteration\")\n",
        "    plt.semilogy(inverse_residuals, label=\"Inverse Iteration\")\n",
        "    plt.semilogy(shifted_residuals, label=\"Shifted Inverse Iteration\")\n",
        "    plt.semilogy(rayleigh_residuals, label=\"Rayleigh Quotient Iteration\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Residual (log scale)\")\n",
        "    plt.title(\"Residuals for Eigenvalue Approximations\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Use a larger 4x4 or 10x10 symmetric matrix\n",
        "#     data = [\n",
        "#     [21, 7, 19, 16, 11, 8, 18, 21, 19, 20, 6, 28, 5, 6, 19, 18, 2, 3, 3, 5],\n",
        "#     [23, 12, 19, 23, 11, 28, 18, 26, 2, 13, 10, 23, 16, 5, 21, 19, 9, 5, 15, 4],\n",
        "#     [19, 6, 26, 28, 19, 22, 2, 28, 20, 16, 2, 18, 27, 24, 19, 15, 3, 26, 9, 6],\n",
        "#     [5, 1, 22, 23, 28, 17, 25, 4, 22, 20, 8, 11, 18, 20, 12, 7, 25, 19, 26, 29],\n",
        "#     [4, 29, 0, 29, 3, 2, 23, 1, 8, 5, 0, 0, 8, 11, 10, 10, 3, 23, 16, 7],\n",
        "#     [15, 7, 0, 27, 15, 7, 22, 16, 9, 27, 8, 15, 6, 7, 27, 17, 20, 6, 17, 5],\n",
        "#     [7, 16, 19, 23, 24, 11, 27, 3, 4, 1, 28, 0, 15, 2, 4, 29, 2, 0, 1, 5],\n",
        "#     [26, 2, 27, 22, 15, 28, 19, 24, 6, 6, 12, 24, 28, 5, 11, 20, 26, 6, 9, 2],\n",
        "#     [11, 27, 14, 19, 7, 14, 18, 15, 12, 26, 28, 4, 18, 0, 13, 16, 0, 14, 14, 4],\n",
        "#     [22, 20, 17, 21, 27, 24, 20, 7, 19, 9, 25, 17, 26, 28, 20, 6, 23, 8, 3, 16],\n",
        "#     [19, 13, 2, 23, 28, 22, 1, 13, 14, 23, 11, 15, 13, 16, 7, 14, 9, 9, 25, 29],\n",
        "#     [16, 4, 2, 12, 29, 25, 1, 9, 11, 9, 26, 15, 17, 12, 29, 17, 25, 22, 11, 28],\n",
        "#     [21, 24, 21, 5, 20, 6, 6, 2, 26, 22, 0, 16, 1, 11, 10, 28, 23, 16, 23, 21],\n",
        "#     [17, 17, 19, 1, 14, 27, 1, 26, 0, 0, 3, 15, 3, 28, 24, 29, 25, 28, 5, 6],\n",
        "#     [12, 10, 25, 12, 21, 25, 14, 18, 15, 6, 28, 14, 0, 22, 18, 13, 22, 29, 18, 4],\n",
        "#     [20, 10, 27, 2, 20, 21, 17, 1, 2, 14, 16, 2, 14, 11, 18, 19, 26, 15, 8, 27],\n",
        "#     [10, 13, 22, 11, 9, 6, 18, 21, 13, 27, 29, 23, 13, 9, 0, 7, 28, 0, 7, 4],\n",
        "#     [5, 26, 20, 2, 10, 21, 11, 8, 16, 16, 19, 27, 29, 1, 26, 23, 12, 4, 24, 22],\n",
        "#     [25, 16, 11, 27, 18, 12, 20, 24, 6, 26, 5, 23, 26, 8, 22, 29, 6, 8, 29, 3],\n",
        "#     [12, 24, 18, 8, 5, 24, 12, 22, 28, 25, 5, 4, 16, 3, 5, 18, 12, 11, 9, 7]\n",
        "# ]\n",
        "    A = np.random.randint(0, 30, (3, 3))\n",
        "    A=[[1,2,3],[0,2,3],[0,0,4]]\n",
        "    A = np.array(A)\n",
        "    for i in A:\n",
        "      print(*i)\n",
        "    A = (A + A.T) / 2  # Symmetrize to ensure real eigenvalues\n",
        "    plot_residuals(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "8QYUFLrZP-bf",
        "outputId": "b0978b59-9a9e-4d40-bd95-314b07840753"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 2 3\n",
            "0 2 3\n",
            "0 0 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B=A\n",
        "print(B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr8264UiUe25",
        "outputId": "cea661c2-20af-4e29-f91c-433bc2703c95"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[21.  15.  19.  10.5  7.5 11.5 12.5 23.5 15.  21.  12.5 22.  13.  11.5\n",
            "  15.5 19.   6.   4.  14.   8.5]\n",
            " [15.  12.  12.5 12.  20.  17.5 17.  14.  14.5 16.5 11.5 13.5 20.  11.\n",
            "  15.5 14.5 11.  15.5 15.5 14. ]\n",
            " [19.  12.5 26.  25.   9.5 11.  10.5 27.5 17.  16.5  2.  10.  24.  21.5\n",
            "  22.  21.  12.5 23.  10.  12. ]\n",
            " [10.5 12.  25.  23.  28.5 22.  24.  13.  20.5 20.5 15.5 11.5 11.5 10.5\n",
            "  12.   4.5 18.  10.5 26.5 18.5]\n",
            " [ 7.5 20.   9.5 28.5  3.   8.5 23.5  8.   7.5 16.  14.  14.5 14.  12.5\n",
            "  15.5 15.   6.  16.5 17.   6. ]\n",
            " [11.5 17.5 11.  22.   8.5  7.  16.5 22.  11.5 25.5 15.  20.   6.  17.\n",
            "  26.  19.  13.  13.5 14.5 14.5]\n",
            " [12.5 17.  10.5 24.  23.5 16.5 27.  11.  11.  10.5 14.5  0.5 10.5  1.5\n",
            "   9.  23.  10.   5.5 10.5  8.5]\n",
            " [23.5 14.  27.5 13.   8.  22.  11.  24.  10.5  6.5 12.5 16.5 15.  15.5\n",
            "  14.5 10.5 23.5  7.  16.5 12. ]\n",
            " [15.  14.5 17.  20.5  7.5 11.5 11.  10.5 12.  22.5 21.   7.5 22.   0.\n",
            "  14.   9.   6.5 15.  10.  16. ]\n",
            " [21.  16.5 16.5 20.5 16.  25.5 10.5  6.5 22.5  9.  24.  13.  24.  14.\n",
            "  13.  10.  25.  12.  14.5 20.5]\n",
            " [12.5 11.5  2.  15.5 14.  15.  14.5 12.5 21.  24.  11.  20.5  6.5  9.5\n",
            "  17.5 15.  19.  14.  15.  17. ]\n",
            " [22.  13.5 10.  11.5 14.5 20.   0.5 16.5  7.5 13.  20.5 15.  16.5 13.5\n",
            "  21.5  9.5 24.  24.5 17.  16. ]\n",
            " [13.  20.  24.  11.5 14.   6.  10.5 15.  22.  24.   6.5 16.5  1.   7.\n",
            "   5.  21.  18.  22.5 24.5 18.5]\n",
            " [11.5 11.  21.5 10.5 12.5 17.   1.5 15.5  0.  14.   9.5 13.5  7.  28.\n",
            "  23.  20.  17.  14.5  6.5  4.5]\n",
            " [15.5 15.5 22.  12.  15.5 26.   9.  14.5 14.  13.  17.5 21.5  5.  23.\n",
            "  18.  15.5 11.  27.5 20.   4.5]\n",
            " [19.  14.5 21.   4.5 15.  19.  23.  10.5  9.  10.  15.   9.5 21.  20.\n",
            "  15.5 19.  16.5 19.  18.5 22.5]\n",
            " [ 6.  11.  12.5 18.   6.  13.  10.  23.5  6.5 25.  19.  24.  18.  17.\n",
            "  11.  16.5 28.   6.   6.5  8. ]\n",
            " [ 4.  15.5 23.  10.5 16.5 13.5  5.5  7.  15.  12.  14.  24.5 22.5 14.5\n",
            "  27.5 19.   6.   4.  16.  16.5]\n",
            " [14.  15.5 10.  26.5 17.  14.5 10.5 16.5 10.  14.5 15.  17.  24.5  6.5\n",
            "  20.  18.5  6.5 16.  29.   6. ]\n",
            " [ 8.5 14.  12.  18.5  6.  14.5  8.5 12.  16.  20.5 17.  16.  18.5  4.5\n",
            "   4.5 22.5  8.  16.5  6.   7. ]]\n"
          ]
        }
      ]
    }
  ]
}